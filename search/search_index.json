{"config":{"lang":["en"],"separator":"[\\s\\-/\\\\]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>      A powerful documentation framework on top of     MkDocs  </p> <p> </p> <p>      Date     01JHQKAE8GKGG9VKPDGBHE8238  </p>"},{"location":"Apache/execute%20script%20from%20html/","title":"execute script from html","text":"<p>used for sending sample logs to Splunk, tested in apache, lighthttpd or ngnix could also be used. </p> index.php<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;style&gt;&lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n\n&lt;h1 style=\"color:blue;\"&gt;Send test Logs to Splunk&lt;/h1&gt;\n\n&lt;h3&gt;Send 7 Logs to Splunk&lt;/h3&gt;\n&lt;form action=\"./script7.php\"&gt;\n    &lt;input type=\"submit\" value=\"Send\"&gt;\n&lt;/form&gt;\n\n&lt;h3&gt;Send 13 Logs to Splunk&lt;/h3&gt;\n&lt;form action=\"./script13.php\"&gt;\n    &lt;input type=\"submit\" value=\"Send\"&gt;\n&lt;/form&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;hr /&gt;\n\n&lt;form method=\"post\" action=\"./script0.php\"&gt;\n\n&lt;label for=\"count\"&gt;Input number of logs to send...&lt;/label&gt;\n&lt;input id=\"count\" type=\"number\" name=\"answer\" min=\"1\" max=\"999\" step=\"9\" /&gt;\n\n&lt;label for=\"delay\"&gt;Do you like a delay?&lt;/label&gt;\n&lt;input id=\"delay\" type=\"number\" name=\"delay\" min=\"1\" max=\"9\" /&gt;\n\n&lt;input type=\"submit\" name=\"submit\" value=\"Submit\"&gt;\n&lt;/form&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;hr /&gt;\n\n&lt;form method=\"post\" action=\"./script0delay.php\"&gt;\n\n&lt;label for=\"delayed\"&gt;Send with 1s delay...&lt;/label&gt;\n&lt;input id=\"delayed\" type=\"number\" name=\"answer\" min=\"1\" max=\"999\" step=\"9\" /&gt;\n&lt;input type=\"submit\" name=\"submit\" value=\"Submit\"&gt;\n&lt;/form&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n&lt;hr /&gt;\n\n\n&lt;/body&gt;\n\n\n&lt;/html&gt;\n</code></pre> <p>php scripts</p> script0.php<pre><code>&lt;?php\nif(isset($_POST['submit']))\n\n$answer=$_POST['answer'];\n  exec(\"/var/www/html/splnk $answer\");\n  header('Location: http://192.168.1.85:8086/index.php');\n?&gt;\n</code></pre> script0delay.php<pre><code>&lt;?php\nif(isset($_POST['submit']))\n\n$answer=$_POST['answer'];\n  exec(\"/var/www/html/splnk_delayed $answer\");\n  header('Location: http://192.168.1.85:8086/index.php');\n?&gt;\n</code></pre> script7.php<pre><code>&lt;?php\n  exec(\"/var/www/html/splnk 7\");\n  header('Location: http://192.168.1.85:8086/index.php');\n?&gt;\n</code></pre> script13.php<pre><code>&lt;?php\n  exec(\"/var/www/html/splnk 13\");\n  header('Location: http://192.168.1.85:8086/index.php');\n?&gt;\n</code></pre> <p>bash script </p> splnk<pre><code>#!/bin/bash\n###########\ncounter=$1\ni=1\nhost=$(hostname)\n\nwhile [ $i -le $counter ]\ndo\n    THEDATE=`date +\"%Y%m%d.%H:%M:%S\"`\n    message=\"$(echo -n $THEDATE) Test log for Splunk from $(echo -n $host) , this is $i of $counter \"\n    curl -s http://192.168.1.85:8088/services/collector/event -H \"Authorization: Splunk 1b627160-517c-443d-ba98-fce35c00f2df\" -d '{ \"event\":\"'\"$message\"'\"}' &gt; /dev/null\n    i=$(( i + 1 ))\ndone\n</code></pre> splnk_delayed<pre><code>#!/bin/bash\n###########\ncounter=$1\ni=1\nhost=$(hostname)\n\nwhile [ $i -le $counter ]\ndo\n    THEDATE=`date +\"%Y%m%d.%H:%M:%S\"`\n    message=\"$(echo -n $THEDATE) Test log for Splunk from $(echo -n $host) , this is $i of $counter \"\n    curl -s http://192.168.1.85:8088/services/collector/event -H \"Authorization: Splunk 1b627160-517c-443d-ba98-fce35c00f2df\" -d '{ \"event\":\"'\"$message\"'\"}' &gt; /dev/null\n    i=$(( i + 1 )) ; sleep 1\ndone\n</code></pre>"},{"location":"Linux/ClearLinuxCache/","title":"Clear Memory Cache, Buffer and Swap Space on Linux.","text":"<p><code>This is not a routine or advisable practice, use only as a last option to clear the buffer and bache.</code></p> <p>Clear PageCache</p> <pre><code>sync; echo 1 &gt; /proc/sys/vm/drop_caches\n</code></pre> <p>Clear Dentries and Inodes</p> <pre><code>sync; echo 2 &gt; /proc/sys/vm/drop_caches\n</code></pre> <p>Clear PageCache, Dentries, and Inodes</p> <pre><code>sync; echo 3 &gt; /proc/sys/vm/drop_caches\n</code></pre> <p>Clear Swap Space</p> <pre><code>swapoff -a &amp;&amp; swapon -a\n</code></pre> <p>use <code>free -h</code> to check the available memory.</p> <pre><code>free -h\n</code></pre>"},{"location":"Linux/Generic/","title":"some basic commands","text":"<p><pre><code>apt-get install net-tools iputils-ping nmon mlocate smartmontools apt-transport-https ca-certificates curl gnupg2 software-properties-common\n</code></pre> <pre><code>ip -c a s\n</code></pre></p>"},{"location":"Linux/Generic/#install-ping","title":"Install Ping","text":""},{"location":"Linux/Generic/#debian","title":"Debian","text":"<pre><code>apt-get install iputils-ping -y\n</code></pre>"},{"location":"Linux/Generic/#rhel-centos","title":"RHEL, CentOS","text":"<pre><code>dnf install iputils -y\n</code></pre>"},{"location":"Linux/Generic/#specify-the-number-of-packets","title":"Specify the Number of Packets","text":"<pre><code>ping -c 1 yahoo.com\n</code></pre>"},{"location":"Linux/Generic/#specify-the-internet-protocol","title":"Specify the Internet Protocol","text":"<p><pre><code>ping -4 yahoo.com\n</code></pre> <pre><code>ping -6 yahoo.com\n</code></pre> <pre><code>ping -4 -c 3 yahoo.com\n</code></pre></p>"},{"location":"Linux/Generic/#filesystem-type-and-size","title":"filesystem type and size","text":"<pre><code>df -Th\n</code></pre>"},{"location":"Linux/Generic/#total-size-of-directories-recursively","title":"total size of directories recursively","text":"<pre><code>du -sh /home/docker\n</code></pre> <p><code>-s</code> to give only the total for each command line argument.   <code>-h</code> for human-readable suffixes like <code>M</code> for megabytes and <code>G</code> for gigabytes (optional).   dotfiles are not included</p>"},{"location":"Linux/Generic/#total-physical-memory","title":"total physical memory","text":"<pre><code>cat /proc/meminfo\n</code></pre> <pre><code>cat /proc/meminfo | head -n 3\n</code></pre> <pre><code>awk '/MemTotal/ {print $2}' /proc/meminfo\n</code></pre> <pre><code>free -h | awk '/Mem\\:/ { print $2 }' \n</code></pre> <pre><code>dmidecode -t 17 | grep  Size:\n</code></pre> <pre><code>lsmem | grep \"Total online memory:\"\n</code></pre>"},{"location":"Linux/Generic/#find-a-string-from-files","title":"find a string from files","text":"<pre><code>find /home/docker/mk/docs/ -type f -exec grep -li 'APACHE' {} \\;\n</code></pre> <p>Search in .txt files only</p> <pre><code>find /home/docker/mk/docs/ -iname \"*.txt\" -type f -exec grep -li 'APACHE' {} \\;\n</code></pre> <p>You can use common parameters such as:</p> <pre><code>-i - Insensitive searching.\n-I - Ignore the binary files.\n-w - Search for the whole words (in the opposite of partial word matching).\n-n - Show the line of your match.\n-C/--context (e.g. -C5) - Increases context, so you see the surrounding code.\n--color=auto - Mark up the matching text.\n-H - Displays filename where the text is found.\n-c - Displays count of matching lines. Can be combined with -H.\n-l - only output the filename where the match was found.\n-h - only output the line which matched (not the filename).\n</code></pre>"},{"location":"Linux/Generic/#find-and-delete-files","title":"find and delete files","text":"<pre><code>find /mnt/Whipple/ -iname Thumbs.db -print -delete\n</code></pre>"},{"location":"Linux/Generic/#find-and-delete-folders","title":"find and delete folders","text":"<pre><code>find /mnt/flanker/Freezer/ -type d -name '@eaDir' -exec rm -rf {} \\;\n</code></pre>"},{"location":"Linux/HDD/","title":"HDD","text":""},{"location":"Linux/HDD/#find-uuid-for-devsdx","title":"Find UUID for /dev/sdX","text":"<pre><code>blkid\n</code></pre> <pre><code>blkid /dev/sdc1\n</code></pre>"},{"location":"Linux/HDD/#list-disks","title":"List Disks","text":"<pre><code>lsblk -p | grep \"disk\"\n</code></pre>"},{"location":"Linux/HDD/#find-the-devsdx-name","title":"Find the /dev/sdX-name","text":"<p>use any of the 3 commands below.</p> <p><pre><code>fdisk -l\n</code></pre> <pre><code>lsblk\n</code></pre> <pre><code>lsblk -p | grep \"disk\"\n</code></pre></p>"},{"location":"Linux/HDD/#initializize-hdd-completely-clear-a-drive","title":"initializize hdd / Completely Clear a Drive","text":"<p><pre><code>YOUR_DEV=/dev/sdX\n</code></pre> <pre><code>dd if=/dev/zero of=$YOUR_DEV bs=512 count=100\n</code></pre> <pre><code>dd if=/dev/zero of=$YOUR_DEV bs=512 seek=$(( $(blockdev --getsz $YOUR_DEV) - 100 )) count=100 \n</code></pre></p>"},{"location":"Linux/HDD/#add-ext4-formatted-synology-disk","title":"Add ext4 formatted Synology Disk","text":"<p>If you try to mount a drive (singele volume/storage pool) used in synology NAS, you will get bellow error.</p> <p><code>mount: unknown filesystem type 'linux_raid_member'</code></p> <p>You should not mount it directly using mount. </p> <p>Install mdadm if not available.</p> <pre><code>apt-get update &amp;&amp; apt-get install mdadm\n</code></pre> <p>Run mdadm to assemble the raid array. </p> <pre><code>mdadm --assemble --run /dev/md0 /dev/sdd3\n</code></pre> <p>When this command is executed successfully, you can mount the created device normally using:</p> <pre><code>mount /dev/md0 /mnt/sdd3\n</code></pre>"},{"location":"Linux/HDD/#unmount-synology-disk","title":"Unmount Synology Disk","text":"<p><pre><code>umount /mnt/sdd3\n</code></pre> <pre><code>mdadm --stop /dev/md0\n</code></pre></p>"},{"location":"Linux/HDD/#umount-target-is-busy","title":"umount target is busy.","text":"<p>But once in a while, you'll come across an error that says 'umount: target is busy': </p> <p>The reason is quite simple! The target device is still in use.</p> <pre><code>$ umount /mnt/flanker\numount: /mnt/flanker: target is busy.\n</code></pre> <p>The best way of unmounting the target in my opinion as you are eventually killing the process itself.</p> <pre><code>$ lsof /mnt/flanker\nCOMMAND     PID USER   FD   TYPE DEVICE SIZE/OFF     NODE NAME\nsmbd    3046726 root   38r   DIR    8,1     4096 52428801 /mnt/flanker/sumo\n</code></pre> <p>Kill the process using PID and un mount the disk</p> <pre><code>kill -9 3046726\n</code></pre> <p>[root@foxy:~]$ fdisk /dev/sda</p> <p>Welcome to fdisk (util-linux 2.38.1). Changes will remain in memory only, until you decide to write them. Be careful before using the write command.</p> <p>This disk is currently in use - repartitioning is probably a bad idea. It's recommended to umount all file systems, and swapoff all swap partitions on this disk.</p> <p>Command (m for help): d</p> <p>Selected partition 1 Partition 1 has been deleted.</p> <p>Command (m for help): p Disk /dev/sda: 2.73 TiB, 3000592982016 bytes, 5860533168 sectors Disk model: WDC WD30EFRX-68E Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 4096 bytes I/O size (minimum/optimal): 4096 bytes / 4096 bytes Disklabel type: gpt Disk identifier: FB47A8C5-CEF0-44C0-B509-584F3DC5976B</p> <p>Command (m for help): w The partition table has been altered. Failed to remove partition 1 from system: Device or resource busy</p> <p>The kernel still uses the old partitions. The new table will be used at the next reboot. Syncing disks.</p> <p>[root@foxy:~]$</p>"},{"location":"Linux/PS1/","title":"PS1","text":"<pre><code>PS1='$ '\n</code></pre> <p>$</p> <p></p> <pre><code>PS1=\"${PURPLE}\\$(date +\\\"%G-%m-%d %T\\\") $GREEN${LOGNAME}$LBLUE@$GREEN$HOSTNAME$PURPLE:${YELLOW}\\$(pwd)\\n$WHITE\"\n</code></pre> <p>2024-02-05 16:04:05 root@localhost:/root  pwd  /root </p> <p></p> <pre><code>PS1=\"\\[\\033[1;34m\\][\\[\\033[1;36m\\]\\u\\[\\033[1;34m\\]@\\[\\033[1;36m\\]\\h\\[\\033[1;34m\\\\]:\\[\\033[1;36m\\]\\w\\[\\033[1;34m\\]]\\[\\033[1;36m\\]$\\[\\033[0m\\] \" \n</code></pre> <p>[root@localhost:~]$</p> <p></p> <pre><code>PS1=\"\\[\\033[1;34m\\][\\[\\033[1;37m\\]\\u\\[\\033[1;34m\\]@\\[\\033[1;33m\\]\"MyVPS\"\\[\\033[1;34m\\\\]:\\[\\033[1;36m\\]\\w\\[\\033[1;34m\\]]\\[\\033[1;36m\\]$\\[\\033[0m\\] \"\n</code></pre> <p>[root@MyVPS:~]$</p>"},{"location":"Linux/PiHole/","title":"PiHole","text":""},{"location":"Linux/PiHole/#export-adlist-domains","title":"Export Adlist Domains","text":"<pre><code>docker exec -it pihole bash\n</code></pre> <pre><code>pihole-FTL sqlite3 /etc/pihole/gravity.db \"SELECT address FROM adlist where enabled=1\"\n</code></pre> <p>With comment</p> <pre><code>pihole-FTL sqlite3 /etc/pihole/gravity.db \"SELECT address,comment FROM adlist where enabled=1\"\n</code></pre> <p>Output</p> <pre><code>https://raw.githubusercontent.com/StevenBlack/hosts/master/hosts\nhttp://sysctl.org/cameleon/hosts\nhttps://adaway.org/hosts.txt\nhttps://v.firebog.net/hosts/AdguardDNS.txt\nhttps://v.firebog.net/hosts/Easyprivacy.txt\nhttps://osint.digitalside.it/Threat-Intel/lists/latestdomains.txt\nhttps://phishing.army/download/phishing_army_blocklist_extended.txt\nhttps://hostfiles.frogeye.fr/firstparty-trackers-hosts.txt\nhttps://raw.githubusercontent.com/FadeMind/hosts.extras/master/add.Spam/hosts\nhttps://urlhaus.abuse.ch/downloads/hostfile/\nhttps://raw.githubusercontent.com/Spam404/lists/master/main-blacklist.txt\nhttps://raw.githubusercontent.com/FadeMind/hosts.extras/master/add.Risk/hosts\nhttps://raw.githubusercontent.com/FadeMind/hosts.extras/master/add.2o7Net/hosts\nhttps://raw.githubusercontent.com/PolishFiltersTeam/KADhosts/master/KADhosts.txt\nhttps://raw.githubusercontent.com/anudeepND/blacklist/master/adservers.txt\nhttps://raw.githubusercontent.com/Sekhan/TheGreatWall/master/TheGreatWall.txt\nhttps://raw.githubusercontent.com/blocklistproject/Lists/master/fraud.txt\nhttps://raw.githubusercontent.com/blocklistproject/Lists/master/malware.txt\nhttps://raw.githubusercontent.com/blocklistproject/Lists/master/redirect.txt\nhttps://raw.githubusercontent.com/blocklistproject/Lists/master/phishing.txt\nhttps://raw.githubusercontent.com/blocklistproject/Lists/master/scam.txt\nhttps://raw.githubusercontent.com/anudeepND/blacklist/master/CoinMiner.txt\nhttps://raw.githubusercontent.com/blocklistproject/Lists/master/ransomware.txt\nhttps://raw.githubusercontent.com/blocklistproject/Lists/master/facebook.txt\nhttps://raw.githubusercontent.com/Perflyst/PiHoleBlocklist/master/SmartTV.txt\nhttps://lists.cyberhost.uk/malware.txt\n\nhttps://raw.githubusercontent.com/StevenBlack/hosts/master/hosts|Default Adlists\nhttp://sysctl.org/cameleon/hosts|Cameleon\nhttps://adaway.org/hosts.txt|Firebog-Advertising Lists\nhttps://v.firebog.net/hosts/AdguardDNS.txt|Firebog-AdguardDNS.\nhttps://v.firebog.net/hosts/Easyprivacy.txt|Tracking &amp;amp; Telemetry Lists\nhttps://osint.digitalside.it/Threat-Intel/lists/latestdomains.txt|Malicious Lists\nhttps://phishing.army/download/phishing_army_blocklist_extended.txt|Malicious Lists\nhttps://raw.githubusercontent.com/crazy-max/WindowsSpyBlocker/master/data/hosts/spy.txt|WindowsSpyBlocker\nhttps://hostfiles.frogeye.fr/firstparty-trackers-hosts.txt|firstparty-trackers\nhttps://raw.githubusercontent.com/FadeMind/hosts.extras/master/add.Spam/hosts|FadeMind Spam\nhttps://urlhaus.abuse.ch/downloads/hostfile/|URLhaus Host file\nhttps://raw.githubusercontent.com/Spam404/lists/master/main-blacklist.txt|Spam404\nhttps://raw.githubusercontent.com/FadeMind/hosts.extras/master/add.Risk/hosts|FadeMind Risk\nhttps://raw.githubusercontent.com/FadeMind/hosts.extras/master/add.2o7Net/hosts|FadeMind add.2o7Net Tracking\nhttps://raw.githubusercontent.com/PolishFiltersTeam/KADhosts/master/KADhosts.txt|kad\nhttps://raw.githubusercontent.com/bongochong/CombinedPrivacyBlockLists/master/NoFormatting/hosts.final|bongochong\nhttps://raw.githubusercontent.com/anudeepND/blacklist/master/adservers.txt|adservers\nhttps://raw.githubusercontent.com/Sekhan/TheGreatWall/master/TheGreatWall.txt|TheGreatWall\nhttps://raw.githubusercontent.com/blocklistproject/Lists/master/fraud.txt|Fraud (blocklist.site)\nhttps://raw.githubusercontent.com/blocklistproject/Lists/master/malware.txt|Malware (blocklist.site)\nhttps://raw.githubusercontent.com/blocklistproject/Lists/master/redirect.txt|Redirect (blocklist.site)\nhttps://raw.githubusercontent.com/blocklistproject/Lists/master/phishing.txt|Phishing (blocklist.site)\nhttps://raw.githubusercontent.com/blocklistproject/Lists/master/scam.txt|Scam(blocklist.site)\nhttps://raw.githubusercontent.com/anudeepND/blacklist/master/CoinMiner.txt|CoinMiner\nhttps://raw.githubusercontent.com/blocklistproject/Lists/master/ransomware.txt|Ransomware\nhttps://raw.githubusercontent.com/blocklistproject/Lists/master/facebook.txt|Facebook.txt\nhttps://raw.githubusercontent.com/RooneyMcNibNug/pihole-stuff/master/anti-bossware.txt|bossware\nhttps://blocklistproject.github.io/Lists/alt-version/tiktok-nl.txt|TikTok\nhttps://raw.githubusercontent.com/Perflyst/PiHoleBlocklist/master/SmartTV.txt|SmartTV\nhttps://raw.githubusercontent.com/crazy-max/WindowsSpyBlocker/refs/heads/master/data/hosts/extra.txt|WindowsSpyBlocker - Hosts extra rules\n</code></pre>"},{"location":"Linux/crontab/","title":"Crontab","text":"<p># List cron jobs of all users</p> <pre><code>for user in $(cut -f1 -d: /etc/passwd)\ndo\n  echo $user\n  crontab -u $user -l\ndone\n</code></pre> <p># Start / Stop containers by adding below using <code>crontab -e</code></p> <pre><code>30 8 * * 1-5 docker start suivi-bourse-app &gt;/dev/null 2&gt;&amp;1\n30 22 * * 1-5 docker stop suivi-bourse-app &gt;/dev/null 2&gt;&amp;1\n</code></pre> <p># copy a crontab from one user to another</p> <pre><code>crontab -u &lt;user1&gt; -l | crontab -u &lt;user2&gt; or crontab -l | ssh $remote_host crontab\n</code></pre> <p># The location of <code>cron</code> files for individual users is in, </p> <p><code>/var/spool/cron/crontabs/</code></p> <p>Each user can have their own crontab, they are not intended to be edited directly."},{"location":"Linux/journalctl/","title":"Journalctl","text":"<p>print the last 10 entries</p> <pre><code>journalctl -n 10\n</code></pre> <p>Print journalctl output directly to the standard output instead of using a pager by including the --no-pager flag. Useful if to process the data further with text processing tools like grep, awk, or sed, or to redirect output to a file.</p> <pre><code>journalctl --no-pager\n</code></pre> <p>View incoming log messages in real-time using -f flag:</p> <pre><code>journalctl -f\n</code></pre> <p>Get the log output in JSON format using the -o option:</p> <pre><code>journalctl -o json -n 10 --no-pager\n</code></pre> <pre><code>journalctl -o json-pretty -n 10 --no-pager\n</code></pre> <p>Check docker service failure, press <code>G</code> to go to the end.</p> <pre><code>journalctl -u docker.service\n</code></pre> <pre><code>journalctl -u ssh.service | tail -n 100\n</code></pre> <p>Journal entries priority level</p> <p>The journalctl command allows filtering records by message priority, as the standard syslog priority levels (listed in descending order):</p> <p><code>{ emerg: 0, alert: 1, crit: 2, error: 3, warning: 4, notice: 5, info: 6, debug: 7 }</code></p> <p>Specify the priority name or its corresponding number value when filtering logs by using the -p option:</p> <pre><code>journalctl -p err` or `$ journalctl -p 3\n</code></pre> description of the levels <pre><code>1.  emerg: the system is unusable.\n2.  alert: action must be taken immediately.\n3.  crit: critical conditions.\n4.  err: error conditions.\n5.  warning: warning conditions.\n6.  notice: normal, but significant condition.\n7.  info: informational message.\n8.  debug: messages that are useful for debugging.\n</code></pre>"},{"location":"Linux/netstat/","title":"Netstat","text":""},{"location":"Linux/netstat/#display-active-network-connections-and-listening-ports-on-a-linux-system","title":"Display active network connections and listening ports on a Linux system.","text":"<pre><code>netstat -tulpn\n</code></pre>"},{"location":"Linux/netstat/#only-want-outbound-tcp-connections-you-can-use","title":"Only want outbound tcp connections you can use","text":"<pre><code>netstat -atn | tr -s ' '| cut -f5 -d ' ' | grep -v '127.0.0.1'\n</code></pre>"},{"location":"Linux/netstat/#that-will-show-all-connections-whose-destination-is-not-the-localhost-can-add-the-internal-ip-also","title":"That will show all connections whose destination is not the localhost, can add the internal ip also.","text":"<pre><code>netstat -atn | tr -s ' '| cut -f5 -d ' ' | grep -v '127.0.0.1\\|192.168.0.15'\n</code></pre>"},{"location":"Linux/netstat/#you-could-also-use","title":"You could also use.","text":"<pre><code>netstat -nputw\n</code></pre>"},{"location":"Linux/netstat/#add-c-switch-to-have-continous-output","title":"add c switch to have continous output","text":"<pre><code>netstat -nputwc\n</code></pre> breakdown of the options <pre><code>a. Display all sockets (both listening and non-listening).\nt. Display TCP connections.\nu. Display UDP connections.\nl. Show only listening sockets.\np. Show the process ID and name for each connection.\nn. Show numerical addresses instead of resolving hosts and ports.\nw. Show raw sockets.\n</code></pre> <p>Note: the netstat command is being phased out, and <code>ss</code> (socket statistics) is recommended as a replacement. <pre><code>ss -tulpn\n</code></pre>"},{"location":"Linux/scripts/","title":"Scripts","text":""},{"location":"Linux/scripts/#sending-test-logs-to-splunk","title":"sending test logs to Splunk","text":"<pre><code>#!/bin/bash\n\ncounter=$1\ni=1\nrel=$(lsb_release -ds)\nhost=$(hostname)\n\nwhile [ $i -le $counter ]\ndo\n    THEDATE=`date +\"%Y%m%d.%H:%M:%S\"`\n    message=\"$(echo -n $THEDATE) Test log for Splunk from $(echo -n $host) using $(echo -n $rel) , this is $i of $counter \"\n    curl -s http://192.168.1.85:8088/services/collector/event -H \"Authorization: Splunk 1b627160-517c-443d-ba98-fce35c00f2df\" -d '{ \"event\":\"'\"$message\"'\"}' &gt; /dev/null\n    i=$(( i + 1 )) ; sleep 1\ndone\n</code></pre>"},{"location":"Linux/scripts/#delete-backups-and-keep-last-3","title":"Delete backups and keep last 3","text":"<pre><code>#!/bin/bash\n\n# Define the directory where backups are stored\nBACKUP_DIR=\"/home/backup\"\n\n# Change to the backup directory\ncd \"$BACKUP_DIR\" || { echo \"Backup directory not found!\"; exit 1; }\n\n# List all files in the directory sorted by modification time (newest first) and exclude the last three\nFILES_TO_DELETE=$(ls -t | tail -n +4)\n\n# Loop through the files and delete them\nIFS=$'\\n'  # Change the Internal Field Separator to handle filenames with spaces\nfor FILE in $FILES_TO_DELETE\ndo\n    echo \"Deleting $FILE\"\n    rm -f \"$FILE\"\ndone\n\necho \"Old backups deleted, keeping the last three most recent ones.\"\n</code></pre>"},{"location":"Linux/smartctl/","title":"S.M.A.R.T","text":"<pre><code>apt-get install smartmontools\n</code></pre> <p><pre><code>smartctl -t short /dev/sdX\n</code></pre> <pre><code>smartctl -t long /dev/sdX\n</code></pre> <pre><code>smartctl -t conveyance /dev/sdX\n</code></pre> <pre><code>badblocks -b 4096 -ws /dev/sdX\n</code></pre></p> <p>Periodically monitor these SMART errors:</p> ID Attribute 5 Reallocated_Sector_Ct 196 Reallocated_Event_Count 197 Current_Pending_Sector 198 Offline_Uncorrectable <p>Shell script for burn-in and testing of drives</p>"},{"location":"Linux/ssh-keygen/","title":"ssh-keygen","text":"<p><pre><code>ssh-keygen -o -a 100 -t ed25519 -f ~/.ssh/id_ed25519 -C \"comment\"\n</code></pre> <pre><code>ssh-keygen -t rsa-sha2-256 -b 4096 -f ~/.ssh/id_rsa2_256 -C \"comment\"\n</code></pre> <pre><code>ssh-keygen -t rsa-sha2-512 -b 4096 -f ~/.ssh/id_rsa2_512 -C \"comment\"\n</code></pre></p> <pre><code>ssh-keygen -o -a 100 -t ed25519 -f ~/.ssh/id_ed25519 -C \"comment\"\nssh-keygen -t rsa-sha2-256 -b 4096 -f ~/.ssh/id_rsa2_256 -C \"comment\"\nssh-keygen -t rsa-sha2-512 -b 4096 -f ~/.ssh/id_rsa2_512 -C \"comment\"\n</code></pre>"},{"location":"Linux/symlink_script/","title":"Symlink script","text":"<p>Create symbolic link for a script to /usr/local/bin so that it can be executed without providing the path.</p> <pre><code>ln -s \"$PWD/myscript.sh\" /usr/local/bin\n</code></pre>"},{"location":"Linux/trusted.gpg/","title":"Key is stored in legacy trusted.gpg keyring","text":"<pre><code>mv /etc/apt/trusted.gpg /etc/apt/trusted.gpg.d/\n</code></pre>"},{"location":"Linux/user/","title":"user creation","text":""},{"location":"Linux/user/#find-user-shells","title":"Find user shells","text":"<pre><code>cut -d\":\" -f 1,7 /etc/passwd\n</code></pre>"},{"location":"Linux/user/#create-user-without-home-directory-and-shell","title":"Create user without home directory and shell","text":"<pre><code>useradd -r -s /bin/false nextcloud\n</code></pre>"},{"location":"Linux/whileLoop/","title":"The while loop, What is it?","text":"<p>Source: Copy/Paste from  Bash Guide for Beginners</p> <p>The while construct allows for repetitive execution of a list of commands, as long as the command controlling the while loop executes successfully (exit status of zero). The syntax is:</p> <p>while CONTROL-COMMAND; do CONSEQUENT-COMMANDS; done</p> <p>CONTROL-COMMAND can be any command(s) that can exit with a success or failure status. The CONSEQUENT-COMMANDS can be any program, script or shell construct.</p> <p>As soon as the CONTROL-COMMAND fails, the loop exits. In a script, the command following the done statement is executed.</p> <p>The return status is the exit status of the last CONSEQUENT-COMMANDS command, or zero if none was executed.</p>"},{"location":"Linux/whileLoop/#simple-example-using-while","title":"Simple example using while","text":"<p>Here is an example for the impatient:</p> <pre><code>#!/bin/bash\n\n# This script opens 4 terminal windows.\n\ni=\"0\"\n\nwhile [ $i -lt 4 ]\ndo\nxterm &amp;\ni=$[$i+1]\ndone\n</code></pre>"},{"location":"Linux/whileLoop/#nested-while-loops","title":"Nested while loops","text":"<p>The example below was written to copy pictures that are made with a webcam to a web directory. Every five minutes a picture is taken. Every hour, a new directory is created, holding the images for that hour. Every day, a new directory is created containing 24 subdirectories. The script runs in the background.</p> <pre><code>#!/bin/bash\n\n# This script copies files from my homedirectory into the webserver directory.\n# (use scp and SSH keys for a remote directory)\n# A new directory is created every hour.\n\nPICSDIR=/home/carol/pics\nWEBDIR=/var/www/carol/webcam\n\nwhile true; do \n    DATE=`date +%Y%m%d`\n    HOUR=`date +%H`\n    mkdir $WEBDIR/\"$DATE\"\n\n    while [ $HOUR -ne \"00\" ]; do \n        DESTDIR=$WEBDIR/\"$DATE\"/\"$HOUR\"\n        mkdir \"$DESTDIR\"\n        mv $PICDIR/*.jpg \"$DESTDIR\"/\n        sleep 3600\n        HOUR=`date +%H`\n    done\ndone\n</code></pre> <p>Note the use of the true statement. This means: continue execution until we are forcibly interrupted (with kill or Ctrl+C).</p> <p>This small script can be used for simulation testing; it generates files:</p> <p><pre><code>#!/bin/bash\n\n# This generates a file every 5 minutes\n\nwhile true; do\ntouch pic-`date +%s`.jpg\nsleep 300\ndone\n</code></pre> Note the use of the date command to generate all kinds of file and directory names. See the man page for more.</p> <p>Note    Use the system</p> <p>The previous example is for the sake of demonstration. Regular checks can easily be achieved using the system's cron facility. Do not forget to redirect output and errors when using scripts that are executed from your crontab!</p>"},{"location":"Linux/whileLoop/#using-keyboard-input-to-control-the-while-loop","title":"Using keyboard input to control the while loop","text":"<p>This script can be interrupted by the user when a Ctrl+C sequence is entered:</p> <pre><code>#!/bin/bash\n\n# This script provides wisdom\n\nFORTUNE=/usr/games/fortune\n\nwhile true; do\necho \"On which topic do you want advice?\"\ncat &lt;&lt; topics\npolitics\nstartrek\nkernelnewbies\nsports\nbofh-excuses\nmagic\nlove\nliterature\ndrugs\neducation\ntopics\n\necho\necho -n \"Make your choice: \"\nread topic\necho\necho \"Free advice on the topic of $topic: \"\necho\n$FORTUNE $topic\necho\n\ndone\n</code></pre> <p>A here document is used to present the user with possible choices. And again, the true test repeats the commands from the CONSEQUENT-COMMANDS list over and over again.</p>"},{"location":"Linux/whileLoop/#calculating-an-average","title":"Calculating an average","text":"<p>This script calculates the average of user input, which is tested before it is processed: if input is not within range, a message is printed. If q is pressed, the loop exits:</p> <pre><code>#!/bin/bash\n\n# Calculate the average of a series of numbers.\n\nSCORE=\"0\"\nAVERAGE=\"0\"\nSUM=\"0\"\nNUM=\"0\"\n\nwhile true; do\n\n  echo -n \"Enter your score [0-100%] ('q' for quit): \"; read SCORE;\n\n  if ((\"$SCORE\" &lt; \"0\"))  || ((\"$SCORE\" &gt; \"100\")); then\n    echo \"Be serious.  Common, try again: \"\n  elif [ \"$SCORE\" == \"q\" ]; then\n    echo \"Average rating: $AVERAGE%.\"\n    break\n  else\n    SUM=$[$SUM + $SCORE]\n    NUM=$[$NUM + 1]\n    AVERAGE=$[$SUM / $NUM]\n  fi\n\ndone\n\necho \"Exiting.\"\n</code></pre> <p>Note how the variables in the last lines are left unquoted in order to do arithmetic.</p>"},{"location":"Miscellaneous/CygWin/","title":"CygWin","text":""},{"location":"Miscellaneous/CygWin/#generate-ssh_config-file-in-etc","title":"generate \"ssh_config\" file in /etc/","text":"<pre><code>ssh-host-config\n</code></pre>"},{"location":"Miscellaneous/Firefox/","title":"Firefox","text":""},{"location":"Miscellaneous/Firefox/#enable-disable-loading-images-in-firefox-browser","title":"Enable / Disable loading images in Firefox browser.","text":"<p>set <code>permissions.default.image</code> pref to 2 using about:config.</p> <p>The default is 1 to allow all images, a value of 2 will block images.</p> <pre><code>1: Allow all images to load, regardless of origin. (Default)\n2: Block all images from loading.\n3: Prevent third-party images from loading.\n</code></pre>"},{"location":"Miscellaneous/Firefox/#about-profiles","title":"About Profiles","text":"<p><code>about:profiles</code> page helps you to manage your profiles.</p>"},{"location":"Miscellaneous/Firefox/#profilesini-file","title":"Profiles.ini file","text":"<p>The <code>profiles.ini</code> file contains information used to keep track of profiles in Firefox.</p> <p>It's located under <code>%APPDATA%\\Mozilla\\Firefox</code></p>"},{"location":"Miscellaneous/LibreELEC/","title":"LibreELEC","text":""},{"location":"Miscellaneous/LibreELEC/#enable-gigabit","title":"Enable gigabit","text":"<p>as of LibreELEC (official): 11.0.6 (Generic.x86_64) gigabit is disabled by default, do below to enable gigabit in LibreELEC.</p> <p><pre><code>mount -o remount,rw /flash\n</code></pre> <pre><code>touch /flash/uEnv.txt\n</code></pre> <pre><code>sed \"s|#enable_giga_arg=fec.disable_giga=0|enable_giga_arg=fec.disable_giga=0|g\" /flash/uEnv.txt\n</code></pre> <pre><code>mount -o remount,ro /flash\n</code></pre></p>"},{"location":"Miscellaneous/MKDocsBuildScript/","title":"MKDocsBuildScript","text":"<p>bash script for  build and upload/update ngnix docker container.</p> <pre><code>#!/bin/bash\ncd /home/docker/mk &amp;&amp; \\\necho $(pwd) &amp;&amp; \\\ndocker run --rm -it -v ./:/docs squidfunk/mkdocs-material build -c &amp;&amp; \\\nrsync -Pavzhe \"ssh -p 22 -i /home/Keys/id_rsa\" --delete /home/docker/mk/site/ root@192.168.7.13:/var/lib/docker/volumes/ngx_nginx-data/_data\n</code></pre>"},{"location":"Miscellaneous/MKDocsImage/","title":"MKDocsImage","text":"LeftRightImage Image, aligned to left<pre><code>![Image title](https://dummyimage.com/600x400/eee/aaa){ align=left }\n</code></pre> <p>Image aligned left.</p> Image, aligned to right<pre><code>![Image title](https://dummyimage.com/600x400/eee/aaa){ align=right }\n</code></pre> <p></p> <p>Image aligned right.</p> Image, aligned to left<pre><code>![Image title](https://dummyimage.com/600x400/eee/aaa){ align=left }\n</code></pre> <p></p> <p>Image aligned left.</p>"},{"location":"Miscellaneous/MarkdownTextColour/","title":"MarkdownTextColour","text":"<p>Adding colour for text in markdown.</p> <p><code> Material for MkDocs .</code> <pre><code>&lt;code&gt;&lt;span style='color:yellow'&gt; Material for MkDocs .&lt;/span&gt;&lt;/code&gt;\n</code></pre></p> <p>Material for MkDocs. <pre><code>&lt;span style=\"color: blue;\"&gt; Material for MkDocs . \n</code></pre> <p> Material for MkDocs. <pre><code>&lt;span style=\"color: purple;\"&gt;Material for MkDocs . \n</code></pre> <p>Some other colours: aqua, olive, teal, lightgreen, lightblue, orange, violet, pink, lime, purple, magenta.</p>"},{"location":"Miscellaneous/PHP%20Remote%20IP/","title":"PHP Remote IP (REMOTE_ADDR)","text":""},{"location":"Miscellaneous/PHP%20Remote%20IP/#return-ip-in-json-format","title":"Return ip in json format","text":"index.php<pre><code>&lt;?php\nheader('Access-Control-Allow-Origin: *');\nheader('Content-type: application/json');\n$remote = $_SERVER[\"REMOTE_ADDR\"] ?? '127.0.0.1';\n    $response = array();\n    $response[0] = array(\n        'id' =&gt; '1',\n        'value1'=&gt; $remote,\n        'value2'=&gt; 'value2'\n    );\n\necho json_encode($response); \n?&gt;\n</code></pre>"},{"location":"Miscellaneous/PHP%20Remote%20IP/#return-ip-alone","title":"Return ip alone","text":"index.php<pre><code>&lt;?\n$remote = $_SERVER[\"REMOTE_ADDR\"] ?? '127.0.0.1';\necho $remote;\n?&gt;\n</code></pre>"},{"location":"Miscellaneous/SQLServer/","title":"MS SQLServer","text":""},{"location":"Miscellaneous/SQLServer/#get-record-count-from-all-tables-ina-database","title":"Get record count from all tables ina Database","text":"<pre><code>SELECT  \n      QUOTENAME(SCHEMA_NAME(sOBJ.schema_id)) + '.' + QUOTENAME(sOBJ.name) AS [TableName]  \n      , SUM(sPTN.Rows) AS [RowCount]  \nFROM   \n      sys.objects AS sOBJ  \n      INNER JOIN sys.partitions AS sPTN  \n            ON sOBJ.object_id = sPTN.object_id  \nWHERE  \n      sOBJ.type = 'U'  \n      AND sOBJ.is_ms_shipped = 0x0  \n      AND index_id &lt; 2 -- 0:Heap, 1:Clustered  \nGROUP BY   \n      sOBJ.schema_id  \n      , sOBJ.name  \nORDER BY [TableName]  \nGO\n</code></pre> <pre><code>SELECT  \n      QUOTENAME(SCHEMA_NAME(sOBJ.schema_id)) + '.' + QUOTENAME(sOBJ.name) AS [TableName]  \n      , SUM(sdmvPTNS.row_count) AS [RowCount]  \nFROM  \n      sys.objects AS sOBJ  \n      INNER JOIN sys.dm_db_partition_stats AS sdmvPTNS  \n            ON sOBJ.object_id = sdmvPTNS.object_id  \nWHERE   \n      sOBJ.type = 'U'  \n      AND sOBJ.is_ms_shipped = 0x0  \n      AND sdmvPTNS.index_id &lt; 2  \nGROUP BY  \n      sOBJ.schema_id  \n      , sOBJ.name  \nORDER BY [TableName]  \nGO\n</code></pre> <p>Below statement provides more details along with the count</p> <pre><code>SELECT DISTINCT SCH.name AS SchemaName  \n      ,OBJ.name AS ObjName  \n      ,OBJ.type_desc AS ObjType  \n      ,INDX.name AS IndexName  \n      ,INDX.type_desc AS IndexType  \n      ,PART.partition_number AS PartitionNumber  \n      ,PART.rows AS PartitionRows  \n      ,STAT.row_count AS StatRowCount  \n      ,STAT.used_page_count * 8 AS UsedSizeKB  \n      ,STAT.reserved_page_count * 8 AS ReservedSizeKB  \n      ,PART.data_compression_desc  \n      ,DS.name AS FilegroupName  \n      ,(STAT.reserved_page_count - STAT.used_page_count) * 8 AS Unused  \nFROM sys.partitions AS PART  \n     INNER JOIN sys.dm_db_partition_stats AS STAT  \n         ON PART.partition_id = STAT.partition_id  \n            AND PART.partition_number = STAT.partition_number  \n     INNER JOIN sys.objects AS OBJ  \n         ON STAT.object_id = OBJ.object_id  \n     INNER JOIN sys.schemas AS SCH  \n         ON OBJ.schema_id = SCH.schema_id  \n     INNER JOIN sys.indexes AS INDX  \n         ON STAT.object_id = INDX.object_id  \n            AND STAT.index_id = INDX.index_id  \n     INNER JOIN sys.data_spaces AS DS  \n         ON INDX.data_space_id = DS.data_space_id  \nORDER BY OBJ.name  \n        ,INDX.name  \n        ,PART.partition_number\n</code></pre>"},{"location":"Miscellaneous/git/","title":"Git","text":""},{"location":"Miscellaneous/git/#init-git-from-the-folder","title":"init git from the folder","text":"<pre><code>git init -b main\n</code></pre>"},{"location":"Miscellaneous/git/#addchange-git-config","title":"add/change git <code>config</code>","text":"<pre><code>[core]\n    repositoryformatversion = 0\n    filemode = false\n    bare = false\n    logallrefupdates = true\n    symlinks = false\n    ignorecase = true\n[remote \"origin\"]\n    url = http://192.168.1.85:3000/giteauser/cargo.git\n    fetch = +refs/heads/*:refs/remotes/origin/*\n[branch \"main\"]\n    remote = origin\n    merge = refs/heads/main\n</code></pre>"},{"location":"Miscellaneous/git/#pull","title":"pull","text":"<pre><code>git pull\n</code></pre>"},{"location":"Miscellaneous/git/#add-all","title":"add all","text":"<pre><code>git add .\n</code></pre>"},{"location":"Miscellaneous/git/#commit","title":"commit","text":"<pre><code>git commit -m \"First commit\"\n</code></pre>"},{"location":"Miscellaneous/git/#push-to-remote","title":"push to remote","text":"<pre><code>git push\n</code></pre>"},{"location":"Miscellaneous/git/#caching-credentials-in-git","title":"Caching credentials in Git","text":"<pre><code>git config --global credential.helper store\n</code></pre>"},{"location":"Miscellaneous/github/","title":"find your comments in github","text":"<pre><code>commenter:your_username repo:immich-app/immich is:issue\n</code></pre>"},{"location":"Miscellaneous/hetzner%20mtu/","title":"Hetzner mtu","text":"<p>I have just had this exact same issue, here is the fix:</p> <p>Hetzner fully supports VXLAN on their private networking. The actual issue is that Docker's default network MTU is 1500, Hetzner's private network MTU is 1450, this will cause problems with Swarm communication.</p> <p>The solution is to set the MTU of any network you create to 1450 in driver opts: docker network <code>create -d overlay --opt com.docker.network.driver.mtu=1450 example-net</code></p> <p>Compose:</p> <pre><code>networks:\n  example_net:\n    driver: overlay\n    driver_opts:\n      com.docker.network.driver.mtu: 1450\n</code></pre> <p>You will also need to replace the default ingress network:</p> <p><code>docker network rm ingress</code></p> <p><code>docker network create -d overlay --ingress --opt com.docker.network.driver.mtu=1450 ingress</code></p>"},{"location":"Miscellaneous/markdown-supported-languages/","title":"Markdown supported languages","text":"<p>Note: The programming languages supported by the markdown depends on the markdown editor you use. The editor need to detect the language and do the syntax highlight.</p>"},{"location":"Miscellaneous/markdown-supported-languages/#heres-a-list-of-languages-supported-by-the-markdown","title":"Here's a list of languages supported by the markdown:","text":"<ul> <li> <p>Cucumber ('*.feature')</p> </li> <li> <p>abap ('*.abap')</p> </li> <li> <p>ada ('.adb', '.ads', '*.ada')</p> </li> <li> <p>ahk ('.ahk', '.ahkl')</p> </li> <li> <p>apacheconf ('.htaccess', 'apache.conf', 'apache2.conf')</p> </li> <li> <p>applescript ('*.applescript')</p> </li> <li> <p>as ('*.as')</p> </li> <li> <p>as3 ('*.as')</p> </li> <li> <p>asy ('*.asy')</p> </li> <li> <p>bash ('.sh', '.ksh', '.bash', '.ebuild', '*.eclass')</p> </li> <li> <p>bat ('.bat', '.cmd')</p> </li> <li> <p>befunge ('*.befunge')</p> </li> <li> <p>blitzmax ('*.bmx')</p> </li> <li> <p>boo ('*.boo')</p> </li> <li> <p>brainfuck ('.bf', '.b')</p> </li> <li> <p>c ('.c', '.h')</p> </li> <li> <p>cfm ('.cfm', '.cfml', '*.cfc')</p> </li> <li> <p>cheetah ('.tmpl', '.spt')</p> </li> <li> <p>cl ('.cl', '.lisp', '*.el')</p> </li> <li> <p>clojure ('.clj', '.cljs')</p> </li> <li> <p>cmake ('*.cmake', 'CMakeLists.txt')</p> </li> <li> <p>coffeescript ('*.coffee')</p> </li> <li> <p>console ('*.sh-session')</p> </li> <li> <p>control ('control')</p> </li> <li> <p>cpp ('.cpp', '.hpp', '.c++', '.h++', '.cc', '.hh', '.cxx', '.hxx', '*.pde')</p> </li> <li> <p>csharp ('*.cs')</p> </li> <li> <p>css ('*.css')</p> </li> <li> <p>cython ('.pyx', '.pxd', '*.pxi')</p> </li> <li> <p>d ('.d', '.di')</p> </li> <li> <p>delphi ('*.pas')</p> </li> <li> <p>diff ('.diff', '.patch')</p> </li> <li> <p>dpatch ('.dpatch', '.darcspatch')</p> </li> <li> <p>duel ('.duel', '.jbst')</p> </li> <li> <p>dylan ('.dylan', '.dyl')</p> </li> <li> <p>erb ('*.erb')</p> </li> <li> <p>erl ('*.erl-sh')</p> </li> <li> <p>erlang ('.erl', '.hrl')</p> </li> <li> <p>evoque ('*.evoque')</p> </li> <li> <p>factor ('*.factor')</p> </li> <li> <p>felix ('.flx', '.flxh')</p> </li> <li> <p>fortran ('.f', '.f90')</p> </li> <li> <p>gas ('.s', '.S')</p> </li> <li> <p>genshi ('*.kid')</p> </li> <li> <p>glsl ('.vert', '.frag', '*.geo')</p> </li> <li> <p>gnuplot ('.plot', '.plt')</p> </li> <li> <p>go ('*.go')</p> </li> <li> <p>groff ('.(1234567)', '.man')</p> </li> <li> <p>haml ('*.haml')</p> </li> <li> <p>haskell ('*.hs')</p> </li> <li> <p>html ('.html', '.htm', '.xhtml', '.xslt')</p> </li> <li> <p>hx ('*.hx')</p> </li> <li> <p>hybris ('.hy', '.hyb')</p> </li> <li> <p>ini ('.ini', '.cfg')</p> </li> <li> <p>io ('*.io')</p> </li> <li> <p>ioke ('*.ik')</p> </li> <li> <p>irc ('*.weechatlog')</p> </li> <li> <p>jade ('*.jade')</p> </li> <li> <p>java ('*.java')</p> </li> <li> <p>js ('*.js')</p> </li> <li> <p>jsp ('*.jsp')</p> </li> <li> <p>lhs ('*.lhs')</p> </li> <li> <p>llvm ('*.ll')</p> </li> <li> <p>logtalk ('*.lgt')</p> </li> <li> <p>lua ('.lua', '.wlua')</p> </li> <li> <p>make ('.mak', 'Makefile', 'makefile', 'Makefile.', 'GNUmakefile')</p> </li> <li> <p>mako ('*.mao')</p> </li> <li> <p>maql ('*.maql')</p> </li> <li> <p>mason ('.mhtml', '.mc', '*.mi', 'autohandler', 'dhandler')</p> </li> <li> <p>markdown ('*.md')</p> </li> <li> <p>modelica ('*.mo')</p> </li> <li> <p>modula2 ('.def', '.mod')</p> </li> <li> <p>moocode ('*.moo')</p> </li> <li> <p>mupad ('*.mu')</p> </li> <li> <p>mxml ('*.mxml')</p> </li> <li> <p>myghty ('*.myt', 'autodelegate')</p> </li> <li> <p>nasm ('.asm', '.ASM')</p> </li> <li> <p>newspeak ('*.ns2')</p> </li> <li> <p>objdump ('*.objdump')</p> </li> <li> <p>objectivec ('*.m')</p> </li> <li> <p>objectivej ('*.j')</p> </li> <li> <p>ocaml ('.ml', '.mli', '.mll', '.mly')</p> </li> <li> <p>ooc ('*.ooc')</p> </li> <li> <p>perl ('.pl', '.pm')</p> </li> <li> <p>php ('.php', '.php(345)')</p> </li> <li> <p>postscript ('.ps', '.eps')</p> </li> <li> <p>pot ('.pot', '.po')</p> </li> <li> <p>pov ('.pov', '.inc')</p> </li> <li> <p>prolog ('.prolog', '.pro', '*.pl')</p> </li> <li> <p>properties ('*.properties')</p> </li> <li> <p>protobuf ('*.proto')</p> </li> <li> <p>py3tb ('*.py3tb')</p> </li> <li> <p>pytb ('*.pytb')</p> </li> <li> <p>python ('.py', '.pyw', '.sc', 'SConstruct', 'SConscript', '.tac')</p> </li> <li> <p>r ('*.R')</p> </li> <li> <p>rb ('.rb', '.rbw', 'Rakefile', '.rake', '.gemspec', '.rbx', '.duby')</p> </li> <li> <p>rconsole ('*.Rout')</p> </li> <li> <p>rebol ('.r', '.r3')</p> </li> <li> <p>redcode ('*.cw')</p> </li> <li> <p>rhtml ('*.rhtml')</p> </li> <li> <p>rst ('.rst', '.rest')</p> </li> <li> <p>sass ('*.sass')</p> </li> <li> <p>scala ('*.scala')</p> </li> <li> <p>scaml ('*.scaml')</p> </li> <li> <p>scheme ('*.scm')</p> </li> <li> <p>scss ('*.scss')</p> </li> <li> <p>smalltalk ('*.st')</p> </li> <li> <p>smarty ('*.tpl')</p> </li> <li> <p>sourceslist ('sources.list')</p> </li> <li> <p>splus ('.S', '.R')</p> </li> <li> <p>sql ('*.sql')</p> </li> <li> <p>sqlite3 ('*.sqlite3-console')</p> </li> <li> <p>squidconf ('squid.conf')</p> </li> <li> <p>ssp ('*.ssp')</p> </li> <li> <p>tcl ('*.tcl')</p> </li> <li> <p>tcsh ('.tcsh', '.csh')</p> </li> <li> <p>tex ('.tex', '.aux', '*.toc')</p> </li> <li> <p>text ('*.txt')</p> </li> <li> <p>v ('.v', '.sv')</p> </li> <li> <p>vala ('.vala', '.vapi')</p> </li> <li> <p>vbnet ('.vb', '.bas')</p> </li> <li> <p>velocity ('.vm', '.fhtml')</p> </li> <li> <p>vim ('*.vim', '.vimrc')</p> </li> <li> <p>xml ('.xml', '.xsl', '.rss', '.xslt', '.xsd', '.wsdl')</p> </li> <li> <p>xquery ('.xqy', '.xquery')</p> </li> <li> <p>xslt ('.xsl', '.xslt')</p> </li> </ul>"},{"location":"Swarm/Docker/","title":"Docker","text":""},{"location":"Swarm/Docker/#install-docker-on-debian","title":"Install Docker on Debian","text":"<pre><code>apt-get update\napt-get install apt-transport-https ca-certificates curl gnupg2 software-properties-common\ncurl -fsSL https://download.docker.com/linux/debian/gpg | apt-key add -\nadd-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stable\"\napt-get update\napt install docker-ce\n</code></pre>"},{"location":"Swarm/Docker/#etcdockerdaemonjson","title":"/etc/docker/daemon.json","text":"<pre><code>{\n  \"dns\" : [\"192.168.1.1\"],\n  \"metrics-addr\" : \"0.0.0.0:9323\",\n  \"insecure-registries\": [\"192.168.1.85:5000\"],\n  \"experimental\" : true\n}\n</code></pre>"},{"location":"Swarm/Docker/#stop-all-docker-containers","title":"Stop all docker containers","text":"<pre><code>docker stop $(docker ps -a -q)\n</code></pre>"},{"location":"Swarm/Docker/#remove-all-docker-containers","title":"Remove all docker containers","text":"<pre><code>docker rm $(docker ps -a -q)\n</code></pre>"},{"location":"Swarm/Docker/#stop-and-remove-all-containers","title":"Stop and Remove all containers","text":"<pre><code>docker stop $(docker ps -a -q) &amp;&amp; docker rm $(docker ps -a -q)\n</code></pre>"},{"location":"Swarm/Docker/#docker-stats","title":"Docker Stats","text":"<p><pre><code>docker stats --no-stream\n</code></pre> <pre><code>docker stats --all --no-stream\n</code></pre> <pre><code>docker stats jellyfin --no-stream --format \"{{ json . }}\" | python3 -m json.tool\n</code></pre> <pre><code>docker stats paperless-ngx --no-stream --format \"{{ json . }}\" | python3 -m json.tool\n</code></pre></p>"},{"location":"Swarm/Docker/#cpus-total-memory","title":"CPUs &amp; Total Memory","text":"<pre><code>docker info | grep -iE \"CPUs|Memory\"\n</code></pre>"},{"location":"Swarm/Docker/#log-type","title":"Log type","text":"<pre><code>docker inspect -f '{{.HostConfig.LogConfig.Type}}' paperless-ngx\n</code></pre>"},{"location":"Swarm/Docker/#logfile-path","title":"logfile path","text":"<pre><code>docker inspect --format='{{.LogPath}}' paperless-ngx\n</code></pre>"},{"location":"Swarm/Docker/#get-size-before-pull","title":"get size before pull","text":"<pre><code>docker manifest inspect -v ghcr.io/gethomepage/homepage:v0.7.3 | grep size | awk -F ':' '{sum+=$NF} END {print sum}' | numfmt --to=iec-i\n</code></pre>"},{"location":"Swarm/NCloud/","title":"Nextcloud 28.0.1","text":""},{"location":"Swarm/NCloud/#create-db-user","title":"Create DB &amp; User","text":"<pre><code>CREATE DATABASE nextclouddb;\nCREATE USER ncdbuser WITH PASSWORD 'My$ecret7ass';\nGRANT ALL PRIVILEGES ON DATABASE nextclouddb TO ncdbuser;\nALTER DATABASE nextclouddb OWNER TO ncdbuser;\nGRANT USAGE ON SCHEMA public TO ncdbuser;\n</code></pre>"},{"location":"Swarm/NCloud/#nc-admin-password","title":"NC admin password","text":"<pre><code>printf \"My$ecret7ass\" | docker secret create nextcloud-admin-password -\n</code></pre>"},{"location":"Swarm/NCloud/#password-for-nc-database","title":"Password for NC Database","text":"<pre><code>printf \"My$ecret7ass\" | docker secret create nextcloud-postgres-password -`  \n</code></pre>"},{"location":"Swarm/NCloud/#create-volume-for-next-cloud-data","title":"Create Volume for next cloud data","text":"<pre><code>docker volume create --driver local --opt type=none --opt device=/home/cargo/nc_nextcloud-data --opt o=bind nextcloud-data\n</code></pre>"},{"location":"Swarm/NCloud/#deploy-nextcloud-swarmyml","title":"deploy nextcloud-swarm.yml","text":"nextcloud-swarm.yml<pre><code>version: '3.8'\n\nx-default-opts:\n  &amp;default-opts\n  # logging:\n    # options:\n      # max-size: \"10m\"\n  logging:\n    driver: \"none\"\n\nnetworks:\n  traefik-network:\n    external: true\n\nvolumes:\n  nextcloud-data:\n    external: true\n\nsecrets:\n  nextcloud-postgres-password:\n    external: true\n  nextcloud-admin-password:\n    external: true\n\nservices:\n  nextcloud:\n    &lt;&lt;: *default-opts\n    image: nextcloud\n    volumes:\n      - nextcloud-data:/var/www/html\n    environment:\n      TZ: \"Europe/Berlin\"\n      POSTGRES_HOST: postgres15\n      DB_PORT: 5432\n      POSTGRES_DB: nextclouddb\n      POSTGRES_USER: nextclouddbuser\n      POSTGRES_PASSWORD_FILE: /run/secrets/nextcloud-postgres-password\n#\n      NEXTCLOUD_ADMIN_USER: ncadmin\n      NEXTCLOUD_ADMIN_PASSWORD_FILE: /run/secrets/nextcloud-admin-password\n      NEXTCLOUD_TRUSTED_DOMAINS: next.example.com\n      TRUSTED_PROXIES: next.example.com\n      OVERWRITECLIURL: https://next.example.com\n      OVERWRITEPROTOCOL: https\n      OVERWRITEHOST: next.example.com\n      REDIS_HOST: redis\n      PHP_MEMORY_LIMIT: 1024M\n      PHP_UPLOAD_LIMIT: 1024M\n      MEMORY_LIMIT: 1024M\n      UPLOAD_MAX_SIZE: 1024M\n#\n    networks:\n      - traefik-network\n    secrets:\n      - nextcloud-postgres-password\n      - nextcloud-admin-password\n    deploy:\n      mode: replicated\n      replicas: 1\n      placement:\n        max_replicas_per_node: 1\n        constraints:\n          - node.hostname == Server001\n      resources:\n        limits:\n          cpus: '1.55'\n          memory: 2G\n        reservations:\n          cpus: '0.55'\n          memory: 512M\n      labels:\n        - \"traefik.enable=true\"\n        - \"traefik.http.routers.nextcloud.rule=Host(`next.example.com`)\"\n        - \"traefik.http.routers.nextcloud.service=nextcloud\"\n        - \"traefik.http.routers.nextcloud.entrypoints=websecure\"\n        - \"traefik.http.services.nextcloud.loadbalancer.server.port=80\"\n        - \"traefik.http.routers.nextcloud.tls=true\"\n        - \"traefik.http.routers.nextcloud.tls.certresolver=letsencrypt\"\n        - \"traefik.http.services.nextcloud.loadbalancer.passhostheader=true\"\n        - \"traefik.http.routers.nextcloud.middlewares=compresstraefik\"\n        - \"traefik.http.middlewares.compresstraefik.compress=true\"\n</code></pre>"},{"location":"Swarm/NCloud/#nextcloud-cron","title":"Nextcloud CRON","text":"<pre><code>DOCKID=$(docker ps -aqf \"name=nc_nextcloud\") &amp;&amp; docker exec -t -u www-data $DOCKID php -f /var/www/html/cron.php &gt;/dev/null 2&gt;&amp;1\n</code></pre>"},{"location":"Swarm/NCloud/#some-occ-commands","title":"Some OCC commands","text":"<pre><code>docker exec -t -u www-data nextcloud php occ db:add-missing-indices\ndocker exec -t -u www-data nextcloud php occ trashbin:cleanup --all-users\ndocker exec -t -u www-data nextcloud php occ files:scan --all\ndocker exec -u 33 nextcloud php occ config:app:set serverinfo token --value CMoqa-FJ24P-pkRGi-TNTfd-e4F7D\ndocker-compose exec -u www-data -it nextcloud php occ security:bruteforce:reset '192.168.1.1'\n</code></pre>"},{"location":"Swarm/Swarm/","title":"Docker Swarm","text":""},{"location":"Swarm/Swarm/#daemonjson-in-all-swarm-nodes","title":"daemon.json in all swarm nodes","text":"<pre><code>{\n  \"dns\" : [\"1.1.1.1\"],\n  \"metrics-addr\" : \"127.0.0.1:9323\",\n  \"userland-proxy\": false,\n  \"experimental\" : true,\n  \"live-restore\": false,\n  \"no-new-privileges\": true,\n  \"icc\": false,\n  \"log-level\": info\n}\n</code></pre> <p> <code>--live-restore</code> daemon configuration is incompatible with swarm mode as of version 24.0.7. If you set it to true docker daemon won't start and youcld use <code>dockerd --debug</code> to see the error."},{"location":"Swarm/Swarm/#create-an-unsecured-network","title":"Create an unsecured network","text":"<pre><code>docker network create insecure --driver overlay --attachable\n</code></pre>"},{"location":"Swarm/Swarm/#create-a-secured-network","title":"Create a secured network","text":"<pre><code>docker network create secure --opt encrypted --driver overlay --attachable\n</code></pre>"},{"location":"Swarm/Swarm/#networks-used","title":"Networks used","text":"<p><pre><code>docker network create postgres15-network --driver overlay --attachable\n</code></pre> <pre><code>docker network create traefik-network --driver overlay --attachable\n</code></pre> <pre><code>docker network create metrics-network --driver overlay --attachable\n</code></pre></p>"},{"location":"Swarm/Swarm/#list-swarm-network","title":"list swarm network","text":"<pre><code>docker network ls --filter driver=overlay --quiet | xargs docker network inspect --format '{{.Name}} {{ .Options }}'\n</code></pre>"},{"location":"Swarm/Swarm/#swarm-deploy","title":"Swarm Deploy","text":"<pre><code>docker stack deploy --compose-file=docker-compose.yml apache2\n</code></pre> <pre><code>docker stack deploy --prune -c /home/swarm/postgre15-swarm.yml db\n</code></pre>"},{"location":"Swarm/Swarm/#list-nodes-with-assigned-labels","title":"List nodes with assigned labels","text":"<pre><code>docker node ls -q | xargs docker node inspect   -f '{{ .ID }} [{{ .Description.Hostname }}]: {{ .Spec.Labels }}'\n</code></pre>"},{"location":"Swarm/Swarm/#drain-all-worker-nodes","title":"Drain all worker nodes","text":"<pre><code>for node in $(docker node ls --filter \"role=worker\" --format \"{{.ID}}\"); do\n    docker node update --availability drain $node\ndone\n</code></pre>"},{"location":"Swarm/Swarm/#active-all-worker-nodes","title":"Active all worker nodes","text":"<pre><code>for node in $(docker node ls --filter \"role=worker\" --format \"{{.ID}}\"); do\n    docker node update --availability active $node\ndone\n</code></pre>"},{"location":"Swarm/Swarm/#stopremove-all-services","title":"Stop/remove all services.","text":"<pre><code>docker service rm $(docker service ls -q)\n</code></pre>"},{"location":"Swarm/Swarm/#swarm-service","title":"Swarm service","text":"<pre><code>docker stack deploy --compose-file=/home/swarm/apache2/docker-compose.yml apache2\n\ndocker service ls\ndocker service ps apache2_apache2\ndocker service rm apache2_apache2\n\ndocker service scale apache2_apache2=2\ndocker service update --replicas=2 apache2_apache2\n</code></pre>"},{"location":"Swarm/Swarm/#run-service-on-a-specific-node","title":"run service on a specific node","text":"<pre><code>docker service create --name registry --publish published=5000,target=5000 --constraint \"node.hostname==Ghost98\" registry:2\n</code></pre>"},{"location":"Swarm/Swarm/#update-replicas","title":"update replicas","text":"<pre><code>docker service update --replicas 2 --constraint-add \"node.hostname != Ghost98\" apache2_apache2\ndocker service update --replicas 2 --constraint-add \"node.hostname != Ghost55\" apache2_apache2\n\ndocker service update --replicas 2 --constraint-add \"node.hostname==Ghost75\" apache2_apache2\n</code></pre>"},{"location":"Swarm/logging/","title":"Logging options in compose","text":""},{"location":"Swarm/logging/#disable-logging","title":"Disable logging","text":"<pre><code>version: '3.8'\n\nx-default-opts:\n  &amp;default-opts\n  logging:\n    driver: \"none\"\n#\nservices:\n  foo:\n    &lt;&lt;: *default-opts\n    image: localhost:5000/image:latest\n</code></pre>"},{"location":"Swarm/logging/#log-in-json-format","title":"Log in json format","text":"<pre><code>version: '3.8'\n\nx-default-opts:\n  &amp;default-opts\n  logging:\n    driver: \"json-file\"\n    options:\n      max-size: \"1m\"\n      max-file: \"1\"\n#\nservices:\n  bar:\n    &lt;&lt;: *default-opts\n    image: localhost:5000/image:latest\n</code></pre>"},{"location":"Swarm/node_exporter/","title":"node-exporter, CADvisor &amp; postgres-exporter in Docker Swarm","text":"<p>Source: Okami101 Blog</p>"},{"location":"Swarm/node_exporter/#script-to-export-node-names-to-prometheus","title":"script to export node names to prometheus","text":"node_exporter_entrypoint<pre><code>#!/bin/sh -e\n\nNODE_NAME=$(cat /etc/nodename)\necho \"node_meta{node_id=\\\"$NODE_ID\\\", container_label_com_docker_swarm_node_id=\\\"$NODE_ID\\\", node_name=\\\"$NODE_NAME\\\"} 1\" &gt; /home/node-meta.prom\n\nset -- /bin/node_exporter \"$@\"\n\nexec \"$@\"\n</code></pre>"},{"location":"Swarm/node_exporter/#deployment-yml-for-node-exporter-cadvisor","title":"deployment yml for node-exporter &amp; CAdvisor","text":"<pre><code>version: '3.8'\n#\nnetworks:\n  metrics-network:\n    driver: overlay\n  traefik-network:\n    external: true\nconfigs:\n  node_exporter_entrypoint:\n    file: ./configs/node-exporter/node_exporter_entrypoint\n#\nservices:\n  cadvisor:\n    image: gcr.io/cadvisor/cadvisor:v0.47.2\n    hostname: \"{{.Node.Hostname}}\"\n    environment:\n      - --housekeeping_interval=30s\n      - --max_housekeeping_interval=35s\n      - --global_housekeeping_interval=30s\n      - --docker_only=true\n      - --store_container_labels=false\n      # - --disable_metrics=percpu,process,sched,tcp,udp,diskIO,disk,network\n      - --disable_metrics=accelerator,cpu_topology,disk,memory_numa,tcp,udp,percpu,sched,process,hugetlb,referenced_memory,resctrl,cpuset,advtcp,memory_numa\n      - --storage_duration=60s\n#\n      - --event_storage_event_limit=default=0\n      - --event_storage_age_limit=default=0\n    # ports:\n    # - published: 8080\n      # target: 8080\n      # mode: host\n    volumes:\n      - /:/rootfs:ro\n      - /var/run/docker.sock:/var/run/docker.sock:ro\n      - /var/run:/var/run:rw\n      - /sys:/sys:ro\n      - /var/lib/docker:/var/lib/docker:ro\n      - /sys/fs/cgroup:/cgroup:ro\n      - /dev/disk/:/dev/disk:ro\n      - /dev/kmsg:/dev/kmsg\n    networks:\n      - metrics-network\n      - traefik-network\n    deploy:\n      mode: global\n      # resources:\n        # limits:\n          # cpus: '0.35'\n          # memory: 100M\n        # reservations:\n          # cpus: '0.15'\n          # memory: 128M\n######\n  node-exporter:\n    image: quay.io/prometheus/node-exporter:v1.7.0\n    environment:\n      - NODE_ID={{.Node.ID}}\n    command: \n      - '--path.procfs=/host/proc'\n      - '--path.rootfs=/rootfs'\n      - '--path.sysfs=/host/sys'\n      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'\n      - '--collector.textfile.directory=/home'\n    volumes:\n      - /:/host:ro,rslave\n      - /proc:/host/proc:ro\n      - /sys:/host/sys:ro\n      - /:/rootfs:ro\n      - /etc/hostname:/etc/nodename\n    configs:\n      - source: node_exporter_entrypoint\n        target: /docker-entrypoint.sh\n    entrypoint:\n      - /bin/sh\n      - /docker-entrypoint.sh\n    networks:\n      - metrics-network\n      - traefik-network\n    deploy:\n      mode: global\n\n##\n  postgres-exporter:\n    image: quay.io/prometheuscommunity/postgres-exporter\n    secrets:\n      - postgres15-password\n    environment:\n      TZ: Europe/Berlin\n      DATA_SOURCE_URI: postgres15:5432/postgres?sslmode=disable\n      DATA_SOURCE_USER: postgres15\n#      DATA_SOURCE_PASS: ${PG_DB_PASSWORD}\n      DATA_SOURCE_PASS_FILE:  /run/secrets/postgres15-password\n    networks:\n      - metrics-network\n      - traefik-network\n    volumes:\n      - /etc/hosts:/etc/hosts\n    ports:\n      - \"9187:9187\"\n    deploy:\n      mode: replicated\n      replicas: 1\n      placement:\n        max_replicas_per_node: 1\n        constraints:\n          - node.hostname == db_server01\n\nsecrets:\n  postgres15-password:\n    external: true\n</code></pre>"},{"location":"Swarm/node_exporter/#add-node-exporter-and-cadvisor-jobs-to-prometheusyml","title":"Add node-exporter and CADvisor jobs to prometheus.yml","text":"<pre><code>  - job_name: \"cadvisor\"\n    dns_sd_configs:\n      - names:\n          - \"tasks.cadvisor\"\n        type: \"A\"\n        port: 8080\n\n  - job_name: \"node-exporter\"\n    dns_sd_configs:\n      - names:\n          - \"tasks.node-exporter\"\n        type: \"A\"\n        port: 9100\n\n  - job_name: \"postgres-exporter-data-01\"\n    static_configs:\n      - targets: [\"postgres-exporter:9187\"]\n</code></pre>"},{"location":"Swarm/security%20scanner/","title":"Docker Security","text":""},{"location":"Swarm/security%20scanner/#docker-bench-for-security","title":"Docker Bench for Security","text":"<p>The Docker Bench for Security is a script that checks for dozens of common best-practices around deploying Docker containers in production. The tests are all automated, and are based on the CIS Docker Benchmark v1.6.0.</p> <pre><code>git clone https://github.com/docker/docker-bench-security.git\ncd docker-bench-security\ndocker build --no-cache -t docker-bench-security .\ndocker-compose run --rm docker-bench-security\n</code></pre>"},{"location":"Swarm/security%20scanner/#aquasectrivy-image-scanner","title":"aquasec/trivy image scanner","text":"<p>Trivy is a comprehensive and versatile security scanner. Trivy has scanners that look for security issues, and targets where it can find those issues.</p> <pre><code>docker run aquasec/trivy image traefik\n</code></pre> <p>use IP address insted of localhost, if you are scanning images from your local registry.</p> <pre><code>docker run aquasec/trivy image 192.168.1.85:5000/zigbee2mqtt:1.35.1\n</code></pre> <p>you might get below error if <code>localhost:5000/image:latest</code> is used.</p> <pre><code>2024-01-19T22:49:16.924Z        FATAL   image scan error: scan error: unable to initialize a scanner: unable to initialize an image scanner: 4 errors occurred:\n        * docker error: unable to inspect the image (localhost:5000/zigbee2mqtt:1.35.1): Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?\n        * containerd error: containerd socket not found: /run/containerd/containerd.sock\n        * podman error: unable to initialize Podman client: no podman socket found: stat podman/podman.sock: no such file or directory\n        * remote error: Get \"https://localhost:5000/v2/\": dial tcp 127.0.0.1:5000: connect: connection refused; Get \"http://localhost:5000/v2/\": dial tcp 127.0.0.1:5000: connect: connection refused\n</code></pre>"},{"location":"Swarm/volume/","title":"Volume","text":""},{"location":"Swarm/volume/#volume-nocopy","title":"volume-nocopy","text":"<p>volume-nocopy   By default, if you attach an empty volume to a container, and files or directories already existed at the mount-path in the container (dst), the Engine copies those files and directories into the volume, allowing the host to access them. Set volume-nocopy to disable copying files from the container's filesystem to the volume and mount the empty volume.</p> <p>A value is optional:</p> <pre><code>true or 1:  Default if you do not provide a value. Disables copying.\nfalse or 0: Enables copying.\n</code></pre> <pre><code>    volumes:\n      - type: volume\n        source: Immich\n        target: /usr/src/app/upload\n        volume:\n          nocopy: false\n      - /etc/localtime:/etc/localtime:ro\n-\n-\n-\nvolumes:\n  pgdata:\n  temp-cache:\n  Immich:\n    driver: local\n    driver_opts:\n      type: \"nfs\"\n      o: \"addr=XXXXXXXX,nolock,soft,rw\"\n      device: \":/mnt/Immich\"\n</code></pre>"},{"location":"Swarm/volume/#create-volume-for-next-cloud-data","title":"Create Volume for next cloud data","text":"<pre><code>docker volume create --driver local --opt type=none --opt device=/home/cargo/nc_nextcloud-data --opt o=bind nextcloud-data\n</code></pre>"},{"location":"Swarm/PostgreSQL/Postgres15/","title":"Postgres15","text":""},{"location":"Swarm/PostgreSQL/Postgres15/#create-db-user-and-grant-access","title":"create db &amp; user and grant access","text":"<pre><code>psql -U postgres15\n\nCREATE DATABASE grafdb;\nCREATE USER grafdbuser WITH PASSWORD 'My$ecret7ass';\nGRANT ALL PRIVILEGES ON DATABASE grafdb TO grafdbuser;\nALTER DATABASE grafdb OWNER TO grafdbuser;\nGRANT USAGE ON SCHEMA public TO grafdbuser;\n</code></pre>"},{"location":"Swarm/PostgreSQL/Postgres15/#from-master-node-find-the-container","title":"From master node find the container","text":"<pre><code>docker service ps db_postgres15 \u00a0--format '{{.Node}} {{.Name}}.{{.ID}}' --no-trunc --filter desired-state=running\n</code></pre>"},{"location":"Swarm/PostgreSQL/Postgres15/#backup-db","title":"Backup DB","text":"<pre><code>DOCKID=$(docker ps -aqf \"name=db_postgres15\") &amp;&amp; docker exec -it $DOCKID pg_dump -d giteadb -U postgres15 | gzip &gt; /srv/postgres_backups/postgres-giteadb-$(date '+%Y-%m-%d_%H-%M').gz\nDOCKID=$(docker ps -aqf \"name=db_postgres15\") &amp;&amp; docker exec -it $DOCKID pg_dump -d grafdb -U postgres15 | gzip &gt; /srv/postgres_backups/postgres-grafdb-$(date '+%Y-%m-%d_%H-%M').gz\nDOCKID=$(docker ps -aqf \"name=db_postgres15\") &amp;&amp; docker exec -it $DOCKID pg_dump -d invidious -U postgres15 | gzip &gt; /srv/postgres_backups/postgres-invidious-$(date '+%Y-%m-%d_%H-%M').gz\nDOCKID=$(docker ps -aqf \"name=db_postgres15\") &amp;&amp; docker exec -it $DOCKID pg_dump -d gotify -U postgres15 | gzip &gt; /srv/postgres_backups/postgres-gotify-$(date '+%Y-%m-%d_%H-%M').gz\nDOCKID=$(docker ps -aqf \"name=db_postgres15\") &amp;&amp; docker exec -it $DOCKID pg_dump -d nextclouddb -U postgres15 | gzip &gt; /srv/postgres_backups/postgres-nextclouddb-$(date '+%Y-%m-%d_%H-%M').gz\n</code></pre>"},{"location":"Swarm/PostgreSQL/Postgres15/#delete-files-older-than-7-days","title":"Delete files older than 7 days","text":"<p><code>find /srv/postgres_backups -type f -mtime +7 | xargs rm -f</code></p>"},{"location":"Swarm/PostgreSQL/Postgres15/#get-container-id","title":"get container id","text":"<p><code>docker ps -aqf \"name=db_postgres15\"</code></p>"},{"location":"Swarm/PostgreSQL/Postgres15/#restore-databasesh","title":"restore-database.sh","text":"<p>to be tested. Taken from heyValdemar</p> restore-database.sh<pre><code>#!/bin/bash\n\nNEXTCLOUD_BACKUPS_CONTAINER=$(docker ps -aqf \"name=nextcloud_backups\")\n\necho \"--&gt; All available database backups:\"\n\nfor entry in $(docker container exec -it $NEXTCLOUD_BACKUPS_CONTAINER sh -c \"ls /srv/nextcloud-postgres/backups/\")\ndo\n  echo \"$entry\"\ndone\n\necho \"--&gt; Copy and paste the backup name from the list above to restore database and press [ENTER]\n--&gt; Example: nextcloud-postgres-backup-YYYY-MM-DD_hh-mm.gz\"\necho -n \"--&gt; \"\n\nread SELECTED_DATABASE_BACKUP\n\necho \"--&gt; $SELECTED_DATABASE_BACKUP was selected\"\n\necho \"--&gt; Scaling service down...\"\ndocker service scale nextcloud_nextcloud=0\n\necho \"--&gt; Restoring database...\"\ndocker exec -it $NEXTCLOUD_BACKUPS_CONTAINER sh -c 'PGPASSWORD=\"$(cat $POSTGRES_PASSWORD_FILE)\" dropdb -h postgres -p 5432 nextclouddb -U nextclouddbuser \\\n&amp;&amp; PGPASSWORD=\"$(cat $POSTGRES_PASSWORD_FILE)\" createdb -h postgres -p 5432 nextclouddb -U nextclouddbuser \\\n&amp;&amp; PGPASSWORD=\"$(cat $POSTGRES_PASSWORD_FILE)\" gunzip -c /srv/nextcloud-postgres/backups/'$SELECTED_DATABASE_BACKUP' | PGPASSWORD=$(cat $POSTGRES_PASSWORD_FILE) psql -h postgres -p 5432 nextclouddb -U nextclouddbuser'\necho \"--&gt; Database recovery completed...\"\n\necho \"--&gt; Scaling service up...\"\ndocker service scale nextcloud_nextcloud=1\n</code></pre>"},{"location":"Swarm/PostgreSQL/Postgres15/#create-gitea-admin-user-using-backend","title":"create gitea admin user using backend","text":"<pre><code>gitea admin user create --username giteaadmin --password \"My$ecret7ass\" --email giteaadmin@example.com --admin\n</code></pre>"},{"location":"Swarm/PostgreSQL/Postgres15Collation/","title":"Postgres15Collation","text":"<p><code>docker exec -it postgres15 /bin/bash</code></p> <pre><code>/bin/psql  --username=admin\n</code></pre> <pre><code>ALTER DATABASE gitea REFRESH COLLATION VERSION;\nALTER DATABASE admin REFRESH COLLATION VERSION;\nALTER DATABASE postgres REFRESH COLLATION VERSION;\nALTER DATABASE paperless REFRESH COLLATION VERSION;\nALTER DATABASE linkwarden REFRESH COLLATION VERSION;\nALTER DATABASE invidious REFRESH COLLATION VERSION;\n</code></pre>"},{"location":"Swarm/PostgreSQL/postgres15auto/","title":"postgres DB backup script","text":"postgres15auto<pre><code>#!/bin/bash\n\nSOURCES=\"giteadb grafdb invidious gotify nextclouddb\"\nTARGET=\"/data/aa525\"\nDOCKID=$(/usr/bin/docker ps -aqf \"name=db_postgres15\")\n\nfor dbid in $SOURCES; do\n    /usr/bin/docker exec -it $DOCKID pg_dump -d $dbid -U postgres15 | gzip &gt; $TARGET/postgres-$dbid-$(date '+%Y-%m-%d_%H-%M').gz\ndone\n</code></pre>"},{"location":"Swarm/PostgreSQL/postgres15auto/#crontab","title":"crontab","text":"<pre><code>0 23 * * * /root/crons/postgres15auto &gt;/dev/null 2&gt;&amp;1\n</code></pre>"},{"location":"WSL/compact_vhdx/","title":"Compact vhdx files","text":"<p>Compact vhdx files to free spcae occupied by Docker Desktop in windows 10.</p> <p>Run below commands using powershell as administrator.</p> <pre><code>wsl --shutdown\n</code></pre> <pre><code>wsl.exe --list --verbose\n</code></pre> <pre><code>diskpart\n</code></pre> <pre><code>select vdisk file=\"D:\\DockerDesktopWSL\\data\\ext4.vhdx\"\n</code></pre> <pre><code>compact vdisk\n</code></pre> <pre><code>exit\n</code></pre>"},{"location":"Windows/batch/","title":"Batch","text":""},{"location":"Windows/batch/#create-folders-named-the-same-as-the-files","title":"Create folders named the same as the files","text":"<pre><code>rem create folders named the same as the files you currently have and move them into the folders.\n@echo off\nfor %%i in (*) do (\n if not \"%%~ni\" == \"organize\" (\n  md \"%%~ni\" &amp;&amp; move \"%%~i\" \"%%~ni\"\n )\n)\n</code></pre>"}]}